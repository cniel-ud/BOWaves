{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook is for running a first try of BOWave on the Frolich et. al data to see if we match their paper's results.\n",
    "This requires 16 < x < 32 gb of RAM. Recommend running on Caviness with --mem=32gb flag set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Load ICs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import BOWaves.utilities.dataloaders as dataloaders\n",
    "import os\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#frolich_ics = {'ICs': np.array([]), 'labels': np.array([])}\n",
    "frolich_ics = {'ICs': [], 'labels': []}\n",
    "\n",
    "#for file in directory frolich data\n",
    "frolich_data = os.listdir('../data/frolich')\n",
    "\n",
    "#filter out subdirectories such as /img\n",
    "frolich_data = [file for file in frolich_data if not os.path.isdir(file)]\n",
    "\n",
    "for file in frolich_data:\n",
    "    ICs, labels = dataloaders.load_and_visualize_mat_file_frolich('../data/frolich/' + file, visualize=False)\n",
    "    frolich_ics['ICs'].extend(ICs)\n",
    "    frolich_ics['labels'].extend(labels)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now create codebooks since we have the ICs and their labels."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First split off 20% for testing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(frolich_ics['ICs'], frolich_ics['labels'], test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now out of the training set, split into the different classes. Frolich's data has 4 classes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if len(X_train) != len(y_train):\n",
    "    raise ValueError('X_train and y_train are not the same length.')\n",
    "\n",
    "# Forgot what the classes were. check on Caviness\n",
    "neural = {'ICs': [], 'centroids': [], 'labels': [], 'shifts': [], 'distances': [], 'inertia': []}\n",
    "blink = {'ICs': [], 'centroids': [], 'labels': [], 'shifts': [], 'distances': [], 'inertia': []}\n",
    "muscle = {'ICs': [], 'centroids': [], 'labels': [], 'shifts': [], 'distances': [], 'inertia': []}\n",
    "mixed = {'ICs': [], 'centroids': [], 'labels': [], 'shifts': [], 'distances': [], 'inertia': []}\n",
    "\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    if y_train[i] == 'neural':\n",
    "        neural['ICs'].append(X_train[i])\n",
    "    elif y_train[i] == 'blink':\n",
    "        blink['ICs'].append(X_train[i])\n",
    "    elif y_train[i] == 'muscle':\n",
    "        muscle['ICs'].append(X_train[i])\n",
    "    elif y_train[i] == 'mixed':\n",
    "        mixed['ICs'].append(X_train[i])\n",
    "    else:\n",
    "        raise ValueError('Unknown class label: ' + y_train[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from BOWaves.sikmeans.sikmeans_core import shift_invariant_k_means\n",
    "metric, init = 'cosine', 'random'\n",
    "num_clusters = 16\n",
    "centroid_len = 256\n",
    "n_runs = 3\n",
    "n_jobs = 1\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "#need to do this per class.\n",
    "neural['centroids'], neural['labels'], neural['shifts'], neural['distances'], neural['inertia'], _ = shift_invariant_k_means(neural['ICs'], num_clusters, centroid_len, metric=metric, init=init, n_init=n_runs, rng=rng,  verbose=True, n_jobs=n_jobs)\n",
    "\n",
    "blink['centroids'], blink['labels'], blink['shifts'], blink['distances'], blink['inertia'], _ = shift_invariant_k_means(blink['ICs'], num_clusters, centroid_len, metric=metric, init=init, n_init=n_runs, rng=rng,  verbose=True, n_jobs=n_jobs)\n",
    "\n",
    "muscle['centroids'], muscle['labels'], muscle['shifts'], muscle['distances'], muscle['inertia'], _ = shift_invariant_k_means(muscle['ICs'], num_clusters, centroid_len, metric=metric, init=init, n_init=n_runs, rng=rng,  verbose=True, n_jobs=n_jobs)\n",
    "\n",
    "mixed['centroids'], mixed['labels'], mixed['shifts'], mixed['distances'], mixed['inertia'], _ = shift_invariant_k_means(mixed['ICs'], num_clusters, centroid_len, metric=metric, init=init, n_init=n_runs, rng=rng,  verbose=True, n_jobs=n_jobs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have the codebooks, let's run the bowav clf code.\n",
    "We want to do leave one subject out cross validation to try and classify the labels on the held out test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, define BOWav to create the bag-of-words representations of the features learned in the codebooks."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from BOWaves.sikmeans.sikmeans_core import _assignment_step\n",
    "\n",
    "def bag_of_waves(codebooks):\n",
    "    \"\"\"\n",
    "    Creates a bag-of-words representation of the input data using the codebooks.\n",
    "\n",
    "    The codebooks are a list of dictionaries, where each dictionary contains the centroids, labels, shifts, distances, and raw ICs of a codebook. Therefore, they're the only thing we need to pass in.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    codebooks\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X: matrix of shape (n_ics, n_features)\n",
    "        The bag-of-words representation of the input data.\n",
    "    \"\"\"\n",
    "\n",
    "    #n_ics is the number of ICs from all classes in the codebooks list\n",
    "    n_ics = sum(len(codebook['ICs']) for codebook in codebooks)\n",
    "\n",
    "    #n_centroids is the number of centroids from all classes in the codebooks list\n",
    "    n_centroids = sum(len(codebook['centroids']) for codebook in codebooks)\n",
    "\n",
    "    x_squared_norms = None\n",
    "    X = np.zeros((n_ics, n_centroids), dtype=codebooks[0]['centroids'].dtype)\n",
    "\n",
    "    for ic in range(n_ics):\n",
    "        for centroid in range(n_centroids):\n",
    "            nu, _, _ = _assignment_step(codebooks[centroid]['ICs'][ic], codebooks[centroid]['centroids'], x_squared_norms, metric='cosine')\n",
    "\n",
    "            nu, counts = np.unique(nu, return_counts=True)\n",
    "\n",
    "            i_feature = nu + centroid * n_centroids\n",
    "            X[ic, i_feature] = counts\n",
    "    return X\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
